# ProactivePodAutoscaler
This project is an application that can autoscale deployments proactively by using CPU utilisation data in order to predict future CPU utilisation and scaling based on that prediction
This Project was ran in a GKE cluster, and scaled the web-ui deployment of a microservice web application called the teastore. Also in the cluster, Prometheus, and Grafana pods were setup as to collect and visualise data, specifically CPU utilisation data. In order to simulate activity on the teastore, Apache Jmeter was used. This activity helped to create a dataset which then could be used to train a LSTM model, which would attempt to predict CPU utilisation of the teastore-webui deployment. Once the LSTM model was trained it was added to the Pod Autoscaler application, then packaged into a docker image, uploaded to a docker repository, and pulled by the pod autoscaler container running on the cluster. Once activity was again simulated, the Pod Autoscaler managed to proactively autoscale the teastore-webui deployment as desired.
